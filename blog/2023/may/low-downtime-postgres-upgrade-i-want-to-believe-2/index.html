<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Low downtime Postgres upgrade: the runbook (part II) - Bruno Luiz Silva</title><meta name=description content="No one is really prepared to upgrade big Postgres instances without downtime. This second part will focus on how to do it the lowest downtime possible."><meta name=author content><link rel=canonical href=https://brunoluiz.net/blog/2023/may/low-downtime-postgres-upgrade-i-want-to-believe-2/><link href=https://brunoluiz.net/css/stylesheet.min.479df382e20c15ef754d9b2dbc0094ba0efd1852d5ae38da2dce805cd10a01bf.css integrity="sha256-R53zguIMFe91TZstvACUug79GFLVrjjaLc6AXNEKAb8=" rel="preload stylesheet" as=style><link rel=apple-touch-icon href=https://brunoluiz.net/apple-touch-icon.png><link rel=icon href=https://brunoluiz.net/favicon.ico><meta name=generator content="Hugo 0.75.1"><meta property="og:title" content="Low downtime Postgres upgrade: the runbook (part II)"><meta property="og:description" content="No one is really prepared to upgrade big Postgres instances without downtime. This second part will focus on how to do it the lowest downtime possible."><meta property="og:type" content="article"><meta property="og:url" content="https://brunoluiz.net/blog/2023/may/low-downtime-postgres-upgrade-i-want-to-believe-2/"><meta property="og:image" content="https://brunoluiz.net/blog/2023/may/low-downtime-postgres-upgrade-i-want-to-believe-2/cover.jpg"><meta property="article:published_time" content="2023-09-03T12:00:00+00:00"><meta property="article:modified_time" content="2023-09-03T12:00:00+00:00"><meta property="og:site_name" content="Bruno Luiz Silva"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://brunoluiz.net/blog/2023/may/low-downtime-postgres-upgrade-i-want-to-believe-2/cover.jpg"><meta name=twitter:title content="Low downtime Postgres upgrade: the runbook (part II)"><meta name=twitter:description content="No one is really prepared to upgrade big Postgres instances without downtime. This second part will focus on how to do it the lowest downtime possible."><meta itemprop=name content="Low downtime Postgres upgrade: the runbook (part II)"><meta itemprop=description content="No one is really prepared to upgrade big Postgres instances without downtime. This second part will focus on how to do it the lowest downtime possible."><meta itemprop=datePublished content="2023-09-03T12:00:00+00:00"><meta itemprop=dateModified content="2023-09-03T12:00:00+00:00"><meta itemprop=wordCount content="2089"><meta itemprop=image content="https://brunoluiz.net/blog/2023/may/low-downtime-postgres-upgrade-i-want-to-believe-2/cover.jpg"><meta itemprop=keywords content></head><body class=single id=top><script>if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><p class=logo><a href=https://brunoluiz.net>Bruno Luiz Silva</a></p><ul class=menu id=menu onscroll=menu_on_scroll()></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Low downtime Postgres upgrade: the runbook (part II)</h1><div class=post-meta><time>September 3, 2023</time>&nbsp;Â·&nbsp;10 min</div></header><div class=post-content><p><a href=https://unsplash.com/photos/RIb4BDwiakQ><img loading=lazy src=./cover.jpg alt="Photo by Florencia Viadana on Unsplash"></a></p><h1 id=low-downtime-postgres-upgrade-i-want-to-believe-part-ii>Low downtime Postgres upgrade: I want to believe (part II)</h1><p>It is 2023 and upgrading Postgres is still a pain. For those using AWS, there is hope, as they <a href=https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/blue-green-deployments.html>started to offer blue/green deployments for MySQL</a>. Alas, this is not available for Postgres yet.</p><p>In the first part, I exposed the most reasonable options, what was used for the upgrade and how it went. In this post, you will find a lengthy step-by-step on how to achieve a Postgres zero-downtime upgrade.</p><h2 id=observations--limitations>Observations & Limitations</h2><ol><li>The following step-by-step is for a Postgres instance with only one database. It might work for multiple databases, but <strong>logical replications only work against one database at a time</strong>.</li><li><strong>Sequence/series data is not replicated.</strong> This means extra steps are required to adjust any column using sequences (included in this guide).</li><li><strong>The schema and DDL commands (the ones which alter the schema) are not replicated.</strong> This means a schema freeze is needed during the database replication.</li><li><strong>Logical replication <a href="https://www.postgresql.org/docs/current/logical-replication-publication.html#:~:text=By%20default%2C%20this%20is%20the%20primary%20key%2C%20if%20there%20is%20one.%20Another%20unique%20index%20(with%20certain%20additional%20requirements)%20can%20also%20be%20set%20to%20be%20the%20replica%20identity.%20If%20the%20table%20does%20not%20have%20any%20suitable%20key%2C%20then%20it%20can%20be%20set%20to%20replica%20identity%20FULL%2C%20which%20means%20the%20entire%20row%20becomes%20the%20key.">will require rows to have a &ldquo;replica identity&rdquo;</a>.</strong> This should be a primary key and if all your tables have one it will not be a problem. If you find a table missing one, you will need to set the identity manually or create a primary key. <a href="https://www.postgresql.org/docs/current/logical-replication-publication.html#:~:text=By%20default%2C%20this%20is%20the%20primary%20key%2C%20if%20there%20is%20one.%20Another%20unique%20index%20(with%20certain%20additional%20requirements)%20can%20also%20be%20set%20to%20be%20the%20replica%20identity.%20If%20the%20table%20does%20not%20have%20any%20suitable%20key%2C%20then%20it%20can%20be%20set%20to%20replica%20identity%20FULL%2C%20which%20means%20the%20entire%20row%20becomes%20the%20key.">Read the documentation to understand the trade-offs</a>.</li><li><strong>Upgrades can&rsquo;t happen if the database already has replication slots:</strong> The team will need to drop existing replication slots by doing <code>SELECT pg_drop_replication_slot(slot_name)</code>.</li></ol><h2 id=pre-setup>Pre-setup</h2><p>There are a few steps you will need to do before even touching Postgres:</p><ol><li><strong>Get hold of the cluster admin password</strong>. This is the user that will be used for all operations. In case of doubt, is the one created by default when you create the RDS Cluster (might be hidden in your Terraform state).</li><li><strong>Decide which version your team wants to update it to</strong>. Most cloud providers allow you to jump multiple versions (in our case, we went from 10 to 14).</li><li><strong>Run a test suite against the desired version and let it soak in development environments for a while.</strong> Although rare, there might be changes that affect your code.</li><li><strong>Create a new set of</strong> <a href=https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/parameter-groups-overview.html><strong>parameter groups</strong></a> <strong>for the desired version.</strong> It can be done in Terraform (<a href=https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/rds_cluster_parameter_group>cluster</a> and <a href=https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_parameter_group>instances</a>) or in the UI. Having it in Terraform makes it easier to replicate these steps later.</li><li><strong>Ensure SOURCE and TARGET live in the same network and correctly set outbound/inbound firewalls.</strong> It&rsquo;s trivial, but you never know if someone has changed something manually (our case).</li><li><strong>Ensure all tables have replica identity correctly set or have a primary key.</strong></li><li><a href=https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.PostgreSQL.html#USER_UpgradeDBInstance.PostgreSQL.MajorVersion.Process><strong>Read the AWS Postgres upgrade guide</strong></a> to get familiarised with its usual process.</li></ol><h2 id=data-integrity>Data integrity</h2><p>The engineering team could only be confident if we proved that the data integrity was kept after the upgrade. We came up with a few scripts which were consolidated in a tool available at <a href=https://github.com/processout/pg-upgrade-data-check><code>processout/pg-upgrade-data-check</code></a>.</p><p>The script compares data from before the replication and after the replication, comparing the hash of all rows in the between the time the database was replicating. It detected issues multiple times in both testing and production rollouts. The caveat is that it relies on an autoincremental key, not working if your tables don&rsquo;t have one.</p><p>In any case, even if this tool does not suit you, <strong>it is very important that the team defines a strategy to prove the data has been kept intact</strong>.</p><h2 id=preparing-the-source-for-replication>Preparing the SOURCE for replication</h2><ol><li>The cluster needs to have logical replication enabled. On AWS RDS, <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.Replication.Logical.html#:~:text=In%20the%20Parameters%20search%20field%2C%20type%20rds%20to%20find%20the%20rds.logical_replication%20parameter.%20The%20default%20value%20for%20this%20parameter%20is%200%2C%20meaning%20that%20it%27s%20turned%20off%20by%20default.">set <code>rds.logical_replication=1</code> in parameter groups</a>. The native equivalent <a href=https://www.postgresql.org/docs/current/runtime-config-wal.html>is setting <code>wal_level=logical</code></a>. Once configured, restart the instances (be careful with the order and failovers).</li><li>Connect to the SOURCE writer instance and confirm that the WAL level is <code>logical</code> by running <code>show wal_level</code>. If it is not, reboot the SOURCE writer instance.</li><li>Create a replication role and grant the correct access.</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>USER</span> replicator <span style=color:#66d9ef>WITH</span> password <span style=color:#e6db74>&#39;password&#39;</span>; <span style=color:#75715e>-- replace this
</span><span style=color:#75715e></span><span style=color:#66d9ef>GRANT</span> rds_replication <span style=color:#66d9ef>TO</span> replicator; <span style=color:#75715e>-- AWS RDS specific
</span><span style=color:#75715e></span><span style=color:#66d9ef>GRANT</span> <span style=color:#66d9ef>USAGE</span> <span style=color:#66d9ef>ON</span> <span style=color:#66d9ef>SCHEMA</span> <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>TO</span> replicator; <span style=color:#75715e>-- the default for Postgres is &lt;public&gt;
</span><span style=color:#75715e></span><span style=color:#66d9ef>GRANT</span> <span style=color:#f92672>&lt;</span>target_database<span style=color:#f92672>&gt;</span> <span style=color:#66d9ef>TO</span> replicator;
<span style=color:#66d9ef>GRANT</span> <span style=color:#66d9ef>SELECT</span> <span style=color:#66d9ef>ON</span> <span style=color:#66d9ef>ALL</span> TABLES <span style=color:#66d9ef>IN</span> <span style=color:#66d9ef>SCHEMA</span> <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>TO</span> replicator;
</code></pre></div><ol start=4><li>If you have any data integrity script, you should run it now. This is because it will capture the state before you start accumulating WAL.</li><li>Create a publication: This is used by the target database to subscribe for changes.</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#66d9ef>CREATE</span> PUBLICATION pub1 <span style=color:#66d9ef>FOR</span> <span style=color:#66d9ef>ALL</span> TABLES;
</code></pre></div><ol start=6><li>Create a replication slot: The write operations will be accumulated in this slot. It will spill out the LSN it started to capture, and it might be handy to keep a note of that.</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#66d9ef>SELECT</span> pg_create_logical_replication_slot(<span style=color:#e6db74>&#39;rep_slot_001&#39;</span>, <span style=color:#e6db74>&#39;pgoutput&#39;</span>);
</code></pre></div><ol start=7><li>At this point, you can already see replication slot stats by doing the following queries:</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#75715e>-- General details about it
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_replication_slots;

<span style=color:#75715e>-- I mostly used the one below to identify the lag
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> slot_name, pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(),restart_lsn)) <span style=color:#66d9ef>AS</span> replicationSlotLag, active <span style=color:#66d9ef>FROM</span> pg_replication_slots;
</code></pre></div><h2 id=create-the-target-database>Create the target database</h2><p><strong>The target will be a clone of the source.</strong> If you are unfamiliar with this concept, look at <a href=https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Clone.html>the RDS Aurora cloning guide</a>. I haven&rsquo;t tested it, but it might also work with native restore.</p><ol><li>Clone the source database: <a href=https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Clone.html#Aurora.Managing.Clone.create>the UI makes it very simple</a>, but check all parameters set up. <a href=https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/rds_cluster#restore_to_point_in_time-argument-reference>Another way is leveraging Terraform for that</a>.</li><li>Once the clone is finished, check the writer instance logs. You should see one of the three messages:</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>... invalid record length at 136/DFC70140: wanted 24, got <span style=color:#ae81ff>0</span> <span style=color:#75715e># usually it always worked with this one</span>
... invalid resource manager ID <span style=color:#ae81ff>48</span> at 3/1B9AF790
</code></pre></div><p>This is <strong>the LSN the target writer instance started with: keep note of this</strong>. It will never match the one from the <code>pg_create_logical_replication_slot</code> output as more operations went through between its creation and the clone. The LSN output will allow you to indicate Postgres to skip all operations up to a certain point after the upgrade, which is the trick of this process. If you don&rsquo;t set it, you might have duplicated data or unique constraint failures.</p><p>Connect to the target and drop the publication and replication slot, as the Aurora clone will also bring those over. <strong>If you don&rsquo;t delete them,</strong> <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.PostgreSQL.html#USER_UpgradeDBInstance.PostgreSQL.MajorVersion.Process:~:text=Handle%20logical%20replication%20slots"><strong>the pre-upgrade checks will fail</strong></a><strong>.</strong></p><pre><code>DROP PUBLICATION pub1;
SELECT pg_drop_replication_slot('rep_slot_001') from pg_replication_slots;
</code></pre><p><strong>Time to upgrade:</strong> Upgrade to the desired version through the UI or terraform, remembering to double-check all the pre-filled settings. <strong>Remember that you need a new set of parameter groups, as each version has its own (pre-setup step 4).</strong> The upgrade will likely take 15-20 minutes.</p><p>Once finished, check if the writer&rsquo;s <code>show wal_level</code> is set to <code>logical</code>. If not, an extra restart will be required on the writer. This was an issue (probably an AWS bug) in all upgrades.</p><p>Before the final steps, don&rsquo;t forget the following:</p><ol><li><strong>Run <code>ANALYSE</code>:</strong> All table statistics are wiped after an upgrade. Those are used to plan queries correctly, and Postgres' performance might be terrible without them.</li><li><strong>Run <code>VACUUM</code>:</strong> This is optional, but if it has been a while since it has been done, this is an excellent opportunity (no live traffic).</li><li><strong>Run benchmarks:</strong> Pick the heaviest and most frequent queries and run some benchmarks against them (post-ANALYSE). The results should be the same, if not better.</li></ol><h2 id=setup-replication-between-source-and-target>Setup replication between SOURCE and TARGET</h2><p>At this point, around 1-2 hours have passed since the replication slot creation. Your clone only has the data until that point. The following steps will flush all operations from the SOURCE into the TARGET, and at the end, both databases should have the same dataset.</p><ol><li><strong>Create the subscription in the target Postgres.</strong> You must replace all <code>$</code> with the correct values. Depending on your Postgres logging setup, <strong>this command might be logged with the plain password (<code>log_statement=ddl</code>, <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.Concepts.PostgreSQL.html#:~:text=Logs%20all%20data%20definition%20language%20(DDL)%20statements%2C%20such%20as%20CREATE%2C%20ALTER%2C%20DROP%2C%20and%20so%20on.">for example</a>)</strong>. The team might be fine to have this password leaked in logs during the whole upgrade process, but remember to delete the account afterwards.</li></ol><pre><code>
CREATE SUBSCRIPTION sub1 CONNECTION 'host=$source_url user=replicator dbname=$db_name password=$replicator_password' PUBLICATION pub1 WITH (
    copy_data = false, -- disable initial COPY
    create_slot = false, -- disable replication_slot creation on PUBLISHER
    enabled = false, -- disabled by default, as we want to tweak the LSN
    connect = true, -- try to connect to the SOURCE
    slot_name = 'rep_slot_001' -- change this according to the replication slot used
);

</code></pre><ol start=2><li>Check if there were no network or access issues through the Postgres logs. Sometimes, it simply hangs on the <code>CREATE SUBSCRIPTION</code> if the SOURCE can&rsquo;t be reached <strong>(see pre-setup step 5)</strong>.</li><li>Advance the SUBSCRIPTION LSN to the value returned on the TARGET boot. As already observed, this will skip operations that would result in duplicated data. <strong>The caveat is that the LSN returned there is sometimes a bit ahead of what it should be, resulting in skipped legit operations. That is why having a data integrity script is very important!</strong></li></ol><pre><code>SELECT pg_replication_origin_advance(
    (SELECT 'pg_'||oid::text AS &quot;external_id&quot; FROM pg_subscription WHERE subname = 'sub1' LIMIT 1),
    $LSN_FROM_STEP_1
);
</code></pre><ol start=4><li>Enable the subscription by executing <code>ALTER SUBSCRIPTION sub1 ENABLE;</code>.</li><li>On the SOURCE, observe the replication slot statistics. It will show the WAL logs being consumed, with the lag between the current LSN and slot LSN decreasing.</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#66d9ef>SELECT</span> slot_name, pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(),restart_lsn)) <span style=color:#66d9ef>AS</span> replicationSlotLag, active <span style=color:#66d9ef>FROM</span> pg_replication_slots;
<span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_stat_replication;
</code></pre></div><ol start=6><li>The operations will have been all flushed once the lag is around kilobytes. <strong>Run your data integrity scripts at this point, as both should contain the same data (with a minor lag).</strong></li></ol><h2 id=finishing-the-process-the-switch>Finishing the process: the switch</h2><p>At this point, both databases will have the same dataset. All this can be done during work hours, while the switch can be done during off-peak.</p><p>You can monitor its progress by using one of the following queries:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#75715e>--
</span><span style=color:#75715e>-- General sync state
</span><span style=color:#75715e>--
</span><span style=color:#75715e></span>
<span style=color:#75715e>-- Q1: Size per table (useful to spot discrepancies after syncing)
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#66d9ef>table_name</span>, pg_relation_size(quote_ident(<span style=color:#66d9ef>table_name</span>)), pg_size_pretty(pg_relation_size(quote_ident(<span style=color:#66d9ef>table_name</span>)))
<span style=color:#66d9ef>FROM</span> information_schema.tables
<span style=color:#66d9ef>WHERE</span> table_schema <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;public&#39;</span>
<span style=color:#66d9ef>ORDER</span> <span style=color:#66d9ef>BY</span> <span style=color:#ae81ff>2</span> <span style=color:#66d9ef>DESC</span>;

<span style=color:#75715e>-- Q2: Total table sizes without indexes (useful to spot discrepancies after syncing)
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#66d9ef>SUM</span>(pg_relation_size(quote_ident(<span style=color:#66d9ef>table_name</span>))) <span style=color:#66d9ef>FROM</span> information_schema.tables <span style=color:#66d9ef>WHERE</span> table_schema <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;public&#39;</span>;

<span style=color:#75715e>--
</span><span style=color:#75715e>-- SOURCE setup
</span><span style=color:#75715e>--
</span><span style=color:#75715e></span>
<span style=color:#75715e>-- Q3 &amp; Q4: Details about the SOURCE publication
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_publication;
<span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_publication_tables;

<span style=color:#75715e>-- Q5: Get SOURCE LSN (useful to compare with the TARGET LSN)
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> pg_current_wal_lsn();

<span style=color:#75715e>--
</span><span style=color:#75715e>-- SOURCE monitoring
</span><span style=color:#75715e>--
</span><span style=color:#75715e></span>
<span style=color:#75715e>-- Q6: Lag between publisher x subscriber
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> slot_name, pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(),restart_lsn)) <span style=color:#66d9ef>AS</span> replicationSlotLag, active <span style=color:#66d9ef>FROM</span> pg_replication_slots;

<span style=color:#75715e>-- Q7: Data about replication slots
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_replication_slots;

<span style=color:#75715e>-- Q8: Data about SOURCE replication status (like lag &amp; current state)
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_stat_replication;

<span style=color:#75715e>--
</span><span style=color:#75715e>-- TARGET monitoring
</span><span style=color:#75715e>--
</span><span style=color:#75715e></span>
<span style=color:#75715e>-- Q9: Active subscription state and configs (similar to pg_publicationn on the SOURCE)
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_subscription;

<span style=color:#75715e>-- Q10: Details on active TARGET subscriptions
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_stat_subscription;

<span style=color:#75715e>-- More here: https://dba.stackexchange.com/questions/314324/monitor-logical-replication-using-lsn
</span></code></pre></div><p>Every company has a different setup, but this is what will be required in broad lines:</p><ol><li><strong>Stop incoming traffic to the database:</strong> scale down the application using it or create a circuit breaker where it is being used.</li><li><strong>Change environment variables:</strong> point to the new database</li><li><strong>Wait for flush:</strong> there might be some in-flight WAL logs. Refer to the above queries to monitor the progress. Ideally the replication slot should be almost empty (around * kB of data)</li><li><strong>Disable subscription:</strong> <code>ALTER SUBSCRIPTION sub1 DISABLE;</code></li><li><strong>Sync all fields using a sequence:</strong> doing this through a SQL script is recommended, as more time spent here = more downtime. The following script can be used</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># Creates script</span>
cat <span style=color:#e6db74>&lt;&lt; EOT &gt;&gt; ./fix_sequences.sql
</span><span style=color:#e6db74>SELECT &#39;SELECT SETVAL(&#39; || quote_literal(s.sequence_schema || &#39;.&#39; || s.sequence_name) || &#39;, COALESCE(MAX(id), 1)) FROM &#39; || quote_ident(t.table_schema) || &#39;.&#39; || quote_ident(t.table_name) || &#39;;&#39; as sql
</span><span style=color:#e6db74>FROM information_schema.sequences s
</span><span style=color:#e6db74>JOIN information_schema.tables t ON t.table_name = REPLACE(sequence_name, &#39;_id_seq&#39;, &#39;&#39;) AND t.table_schema = s.sequence_schema
</span><span style=color:#e6db74>ORDER BY sequence_name ASC;
</span><span style=color:#e6db74>-- This could be used as well: https://wiki.postgresql.org/wiki/Fixing_Sequences
</span><span style=color:#e6db74>-- But it missed some sequences when I tried
</span><span style=color:#e6db74>EOT</span>

<span style=color:#75715e># Query database and generate sequences to be fixed</span>
psql -Atq -f ./fix_sequences.sql -o ./fix_sequences.gen.sql $target_url
psql -f ./fix_sequences.gen.sql $target_url
</code></pre></div><ol start=6><li><strong>Restart traffic to the database:</strong> If everything goes right, you should be ready to re-enable connections to it.</li></ol><p>Between (5) and (6), you can set up a &ldquo;reverse logical replication&rdquo;, which might help in case of rollback. SOURCE becomes the TARGET, and TARGET becomes the SOURCE. If you want to set this up, script it so you can reduce downtime.</p><h2 id=the-end>The end?</h2><p>If everything goes right, no data is lost, and there is minimal downtime, the team and stakeholders will be happy. This is a reminder: Postgres releases new versions yearly, and AWS will keep phasing old versions out annually. Until a major upgrade allows an easier upgrade path, be prepared for this process more than once in your lifetime ð¥²</p></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://brunoluiz.net>Bruno Luiz Silva</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugoï¸ï¸</a>ï¸</span>
<span>&#183;</span>
<span>Themeï¸ <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top"><button class=top-link id=top-link type=button><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6"><path d="M12 6H0l6-6z"/></svg></button></a>
<script src=https://brunoluiz.net/js/highlight.min.min.e7afc2928c0925d65c4732dfebe147014d91299a98e819e4b42f25c4fa68e91c.js integrity="sha256-56/CkowJJdZcRzLf6+FHAU2RKZqY6BnktC8lxPpo6Rw="></script><script>hljs.initHighlightingOnLoad();</script><script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();document.querySelector(this.getAttribute("href")).scrollIntoView({behavior:"smooth"});});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script><script data-goatcounter=https://brunoluiz.goatcounter.com/count async src=//gc.zgo.at/count.js></script></body></html>