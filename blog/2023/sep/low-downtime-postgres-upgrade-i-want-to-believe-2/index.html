<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Low downtime Postgres upgrade: the runbook (part II) | Bruno Luiz Silva</title><meta name=keywords content><meta name=description content="No one is really prepared to upgrade big Postgres instances without downtime. This second part will focus on how to do it the lowest downtime possible."><meta name=author content><link rel=canonical href=https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://brunoluiz.net/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://brunoluiz.net/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://brunoluiz.net/favicon-32x32.png><link rel=apple-touch-icon href=https://brunoluiz.net/apple-touch-icon.png><link rel=mask-icon href=https://brunoluiz.net/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/"><meta property="og:site_name" content="Bruno Luiz Silva"><meta property="og:title" content="Low downtime Postgres upgrade: the runbook (part II)"><meta property="og:description" content="No one is really prepared to upgrade big Postgres instances without downtime. This second part will focus on how to do it the lowest downtime possible."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2023-09-03T12:00:00+00:00"><meta property="article:modified_time" content="2023-09-03T12:00:00+00:00"><meta property="og:image" content="https://brunoluiz.net/cover.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://brunoluiz.net/cover.jpg"><meta name=twitter:title content="Low downtime Postgres upgrade: the runbook (part II)"><meta name=twitter:description content="No one is really prepared to upgrade big Postgres instances without downtime. This second part will focus on how to do it the lowest downtime possible."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://brunoluiz.net/blog/"},{"@type":"ListItem","position":2,"name":"Low downtime Postgres upgrade: the runbook (part II)","item":"https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Low downtime Postgres upgrade: the runbook (part II)","name":"Low downtime Postgres upgrade: the runbook (part II)","description":"No one is really prepared to upgrade big Postgres instances without downtime. This second part will focus on how to do it the lowest downtime possible.","keywords":[],"articleBody":" It is 2023 and upgrading Postgres is still a pain. For those using AWS, there is hope, as they started to offer blue/green deployments for MySQL. Alas, this is not available for Postgres yet.\nIn the first part, I exposed the most reasonable options, what was used for the upgrade and how it went. In this post, you will find a lengthy step-by-step on how to achieve a Postgres zero-downtime upgrade.\nObservations \u0026 Limitations The following step-by-step is for a Postgres instance with only one database. It might work for multiple databases, but logical replications only work against one database at a time. Sequence/series data is not replicated. This means extra steps are required to adjust any column using sequences (included in this guide). The schema and DDL commands (the ones which alter the schema) are not replicated. This means a schema freeze is needed during the database replication. Logical replication will require rows to have a “replica identity”. This should be a primary key and if all your tables have one it will not be a problem. If you find a table missing one, you will need to set the identity manually or create a primary key. Read the documentation to understand the trade-offs. Upgrades can’t happen if the database already has replication slots: The team will need to drop existing replication slots by doing SELECT pg_drop_replication_slot(slot_name). Pre-setup There are a few steps you will need to do before even touching Postgres:\nGet hold of the cluster admin password. This is the user that will be used for all operations. In case of doubt, is the one created by default when you create the RDS Cluster (might be hidden in your Terraform state). Decide which version your team wants to update it to. Most cloud providers allow you to jump multiple versions (in our case, we went from 10 to 14). Run a test suite against the desired version and let it soak in development environments for a while. Although rare, there might be changes that affect your code. Create a new set of parameter groups for the desired version. It can be done in Terraform (cluster and instances) or in the UI. Having it in Terraform makes it easier to replicate these steps later. Ensure SOURCE and TARGET live in the same network and correctly set outbound/inbound firewalls. It’s trivial, but you never know if someone has changed something manually (our case). Ensure all tables have replica identity correctly set or have a primary key. Read the AWS Postgres upgrade guide to get familiarised with its usual process. Data integrity The engineering team could only be confident if we proved that the data integrity was kept after the upgrade. We came up with a few scripts which were consolidated in a tool available at processout/pg-upgrade-data-check.\nThe script compares data from before the replication and after the replication, comparing the hash of all rows in the between the time the database was replicating. It detected issues multiple times in both testing and production rollouts. The caveat is that it relies on an autoincremental key, not working if your tables don’t have one.\nIn any case, even if this tool does not suit you, it is very important that the team defines a strategy to prove the data has been kept intact.\nPreparing the SOURCE for replication The cluster needs to have logical replication enabled. On AWS RDS, set rds.logical_replication=1 in parameter groups. The native equivalent is setting wal_level=logical. Once configured, restart the instances (be careful with the order and failovers). Connect to the SOURCE writer instance and confirm that the WAL level is logical by running show wal_level. If it is not, reboot the SOURCE writer instance. Create a replication role and grant the correct access. CREATE USER replicator WITH password 'password'; -- replace this GRANT rds_replication TO replicator; -- AWS RDS specific GRANT USAGE ON SCHEMA public TO replicator; -- the default for Postgres is GRANT \u003ctarget_database\u003e TO replicator; GRANT SELECT ON ALL TABLES IN SCHEMA public TO replicator; If you have any data integrity script, you should run it now. This is because it will capture the state before you start accumulating WAL. Create a publication: This is used by the target database to subscribe for changes. CREATE PUBLICATION pub1 FOR ALL TABLES; Create a replication slot: The write operations will be accumulated in this slot. It will spill out the LSN it started to capture, and it might be handy to keep a note of that. SELECT pg_create_logical_replication_slot('rep_slot_001', 'pgoutput'); At this point, you can already see replication slot stats by doing the following queries: -- General details about it SELECT * FROM pg_replication_slots; -- I mostly used the one below to identify the lag SELECT slot_name, pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(),restart_lsn)) AS replicationSlotLag, active FROM pg_replication_slots; Create the target database The target will be a clone of the source. If you are unfamiliar with this concept, look at the RDS Aurora cloning guide. I haven’t tested it, but it might also work with native restore.\nClone the source database: the UI makes it very simple, but check all parameters set up. Another way is leveraging Terraform for that. Once the clone is finished, check the writer instance logs. You should see one of the three messages: ... invalid record length at 136/DFC70140: wanted 24, got 0 # usually it always worked with this one ... invalid resource manager ID 48 at 3/1B9AF790 This is the LSN the target writer instance started with: keep note of this. It will never match the one from the pg_create_logical_replication_slot output as more operations went through between its creation and the clone. The LSN output will allow you to indicate Postgres to skip all operations up to a certain point after the upgrade, which is the trick of this process. If you don’t set it, you might have duplicated data or unique constraint failures.\nConnect to the target and drop the publication and replication slot, as the Aurora clone will also bring those over. If you don’t delete them, the pre-upgrade checks will fail.\nDROP PUBLICATION pub1; SELECT pg_drop_replication_slot('rep_slot_001') from pg_replication_slots; Time to upgrade: Upgrade to the desired version through the UI or terraform, remembering to double-check all the pre-filled settings. Remember that you need a new set of parameter groups, as each version has its own (pre-setup step 4). The upgrade will likely take 15-20 minutes.\nOnce finished, check if the writer’s show wal_level is set to logical. If not, an extra restart will be required on the writer. This was an issue (probably an AWS bug) in all upgrades.\nBefore the final steps, don’t forget the following:\nRun ANALYSE: All table statistics are wiped after an upgrade. Those are used to plan queries correctly, and Postgres’ performance might be terrible without them. Run VACUUM: This is optional, but if it has been a while since it has been done, this is an excellent opportunity (no live traffic). Run benchmarks: Pick the heaviest and most frequent queries and run some benchmarks against them (post-ANALYSE). The results should be the same, if not better. Setup replication between SOURCE and TARGET At this point, around 1-2 hours have passed since the replication slot creation. Your clone only has the data until that point. The following steps will flush all operations from the SOURCE into the TARGET, and at the end, both databases should have the same dataset.\nCreate the subscription in the target Postgres. You must replace all $ with the correct values. Depending on your Postgres logging setup, this command might be logged with the plain password (log_statement=ddl, for example). The team might be fine to have this password leaked in logs during the whole upgrade process, but remember to delete the account afterwards. CREATE SUBSCRIPTION sub1 CONNECTION 'host=$source_url user=replicator dbname=$db_name password=$replicator_password' PUBLICATION pub1 WITH ( copy_data = false, -- disable initial COPY create_slot = false, -- disable replication_slot creation on PUBLISHER enabled = false, -- disabled by default, as we want to tweak the LSN connect = true, -- try to connect to the SOURCE slot_name = 'rep_slot_001' -- change this according to the replication slot used ); Check if there were no network or access issues through the Postgres logs. Sometimes, it simply hangs on the CREATE SUBSCRIPTION if the SOURCE can’t be reached (see pre-setup step 5). Advance the SUBSCRIPTION LSN to the value returned on the TARGET boot. As already observed, this will skip operations that would result in duplicated data. The caveat is that the LSN returned there is sometimes a bit ahead of what it should be, resulting in skipped legit operations. That is why having a data integrity script is very important! SELECT pg_replication_origin_advance( (SELECT 'pg_'||oid::text AS \"external_id\" FROM pg_subscription WHERE subname = 'sub1' LIMIT 1), $LSN_FROM_STEP_1 ); Enable the subscription by executing ALTER SUBSCRIPTION sub1 ENABLE;. On the SOURCE, observe the replication slot statistics. It will show the WAL logs being consumed, with the lag between the current LSN and slot LSN decreasing. SELECT slot_name, pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(),restart_lsn)) AS replicationSlotLag, active FROM pg_replication_slots; SELECT * FROM pg_stat_replication; The operations will have been all flushed once the lag is around kilobytes. Run your data integrity scripts at this point, as both should contain the same data (with a minor lag). Finishing the process: the switch At this point, both databases will have the same dataset. All this can be done during work hours, while the switch can be done during off-peak.\nYou can monitor its progress by using one of the following queries:\n-- -- General sync state -- -- Q1: Size per table (useful to spot discrepancies after syncing) SELECT table_name, pg_relation_size(quote_ident(table_name)), pg_size_pretty(pg_relation_size(quote_ident(table_name))) FROM information_schema.tables WHERE table_schema = 'public' ORDER BY 2 DESC; -- Q2: Total table sizes without indexes (useful to spot discrepancies after syncing) SELECT SUM(pg_relation_size(quote_ident(table_name))) FROM information_schema.tables WHERE table_schema = 'public'; -- -- SOURCE setup -- -- Q3 \u0026 Q4: Details about the SOURCE publication SELECT * FROM pg_publication; SELECT * FROM pg_publication_tables; -- Q5: Get SOURCE LSN (useful to compare with the TARGET LSN) SELECT pg_current_wal_lsn(); -- -- SOURCE monitoring -- -- Q6: Lag between publisher x subscriber SELECT slot_name, pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(),restart_lsn)) AS replicationSlotLag, active FROM pg_replication_slots; -- Q7: Data about replication slots SELECT * FROM pg_replication_slots; -- Q8: Data about SOURCE replication status (like lag \u0026 current state) SELECT * FROM pg_stat_replication; -- -- TARGET monitoring -- -- Q9: Active subscription state and configs (similar to pg_publicationn on the SOURCE) SELECT * FROM pg_subscription; -- Q10: Details on active TARGET subscriptions SELECT * FROM pg_stat_subscription; -- More here: https://dba.stackexchange.com/questions/314324/monitor-logical-replication-using-lsn Every company has a different setup, but this is what will be required in broad lines:\nStop incoming traffic to the database: scale down the application using it or create a circuit breaker where it is being used. Change environment variables: point to the new database Wait for flush: there might be some in-flight WAL logs. Refer to the above queries to monitor the progress. Ideally the replication slot should be almost empty (around * kB of data) Disable subscription: ALTER SUBSCRIPTION sub1 DISABLE; Sync all fields using a sequence: doing this through a SQL script is recommended, as more time spent here = more downtime. The following script can be used # Creates script cat \u003c\u003c EOT \u003e\u003e ./fix_sequences.sql SELECT 'SELECT SETVAL(' || quote_literal(s.sequence_schema || '.' || s.sequence_name) || ', COALESCE(MAX(id), 1)) FROM ' || quote_ident(t.table_schema) || '.' || quote_ident(t.table_name) || ';' as sql FROM information_schema.sequences s JOIN information_schema.tables t ON t.table_name = REPLACE(sequence_name, '_id_seq', '') AND t.table_schema = s.sequence_schema ORDER BY sequence_name ASC; -- This could be used as well: https://wiki.postgresql.org/wiki/Fixing_Sequences -- But it missed some sequences when I tried EOT # Query database and generate sequences to be fixed psql -Atq -f ./fix_sequences.sql -o ./fix_sequences.gen.sql $target_url psql -f ./fix_sequences.gen.sql $target_url Restart traffic to the database: If everything goes right, you should be ready to re-enable connections to it. Between (5) and (6), you can set up a “reverse logical replication”, which might help in case of rollback. SOURCE becomes the TARGET, and TARGET becomes the SOURCE. If you want to set this up, script it so you can reduce downtime.\nThe end? If everything goes right, no data is lost, and there is minimal downtime, the team and stakeholders will be happy. This is a reminder: Postgres releases new versions yearly, and AWS will keep phasing old versions out annually. Until a major upgrade allows an easier upgrade path, be prepared for this process more than once in your lifetime 🥲\n","wordCount":"2079","inLanguage":"en","image":"https://brunoluiz.net/cover.jpg","datePublished":"2023-09-03T12:00:00Z","dateModified":"2023-09-03T12:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/"},"publisher":{"@type":"Organization","name":"Bruno Luiz Silva","logo":{"@type":"ImageObject","url":"https://brunoluiz.net/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://brunoluiz.net/ accesskey=h title="Bruno Luiz Silva (Alt + H)">Bruno Luiz Silva</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Low downtime Postgres upgrade: the runbook (part II)</h1><div class=post-meta><span title='2023-09-03 12:00:00 +0000 UTC'>September 3, 2023</span>&nbsp;·&nbsp;10 min</div></header><figure class=entry-cover><img loading=eager srcset='https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/cover_hu_f518b60903239b39.jpg 360w,https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/cover_hu_cdb2113e61c0abf0.jpg 480w,https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/cover_hu_4c8abb757025ce50.jpg 720w,https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/cover_hu_14333f66c1f4918e.jpg 1080w,https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/cover_hu_1ac35bbf78e6234f.jpg 1500w,https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/cover.jpg 1536w' src=https://brunoluiz.net/blog/2023/sep/low-downtime-postgres-upgrade-i-want-to-believe-2/cover.jpg sizes="(min-width: 768px) 720px, 100vw" width=1536 height=807 alt="Photo by Florencia Viadana on Unsplash"><figcaption><a href=https://unsplash.com/photos/RIb4BDwiakQ>Photo by Florencia Viadana on Unsplash</a></figcaption></figure><div class=post-content><p>It is 2023 and upgrading Postgres is still a pain. For those using AWS, there is hope, as they <a href=https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/blue-green-deployments.html>started to offer blue/green deployments for MySQL</a>. Alas, this is not available for Postgres yet.</p><p><a href=https://brunoluiz.net/blog/2022/nov/low-downtime-postgres-upgrade-i-want-to-believe/>In the first part, I exposed the most reasonable options, what was used for the upgrade and how it went</a>. In this post, you will find a lengthy step-by-step on how to achieve a Postgres zero-downtime upgrade.</p><h2 id=observations--limitations>Observations & Limitations<a hidden class=anchor aria-hidden=true href=#observations--limitations>#</a></h2><ol><li>The following step-by-step is for a Postgres instance with only one database. It might work for multiple databases, but <strong>logical replications only work against one database at a time</strong>.</li><li><strong>Sequence/series data is not replicated.</strong> This means extra steps are required to adjust any column using sequences (included in this guide).</li><li><strong>The schema and DDL commands (the ones which alter the schema) are not replicated.</strong> This means a schema freeze is needed during the database replication.</li><li><strong>Logical replication <a href="https://www.postgresql.org/docs/current/logical-replication-publication.html#:~:text=By%20default%2C%20this%20is%20the%20primary%20key%2C%20if%20there%20is%20one.%20Another%20unique%20index%20(with%20certain%20additional%20requirements)%20can%20also%20be%20set%20to%20be%20the%20replica%20identity.%20If%20the%20table%20does%20not%20have%20any%20suitable%20key%2C%20then%20it%20can%20be%20set%20to%20replica%20identity%20FULL%2C%20which%20means%20the%20entire%20row%20becomes%20the%20key.">will require rows to have a &ldquo;replica identity&rdquo;</a>.</strong> This should be a primary key and if all your tables have one it will not be a problem. If you find a table missing one, you will need to set the identity manually or create a primary key. <a href="https://www.postgresql.org/docs/current/logical-replication-publication.html#:~:text=By%20default%2C%20this%20is%20the%20primary%20key%2C%20if%20there%20is%20one.%20Another%20unique%20index%20(with%20certain%20additional%20requirements)%20can%20also%20be%20set%20to%20be%20the%20replica%20identity.%20If%20the%20table%20does%20not%20have%20any%20suitable%20key%2C%20then%20it%20can%20be%20set%20to%20replica%20identity%20FULL%2C%20which%20means%20the%20entire%20row%20becomes%20the%20key.">Read the documentation to understand the trade-offs</a>.</li><li><strong>Upgrades can&rsquo;t happen if the database already has replication slots:</strong> The team will need to drop existing replication slots by doing <code>SELECT pg_drop_replication_slot(slot_name)</code>.</li></ol><h2 id=pre-setup>Pre-setup<a hidden class=anchor aria-hidden=true href=#pre-setup>#</a></h2><p>There are a few steps you will need to do before even touching Postgres:</p><ol><li><strong>Get hold of the cluster admin password</strong>. This is the user that will be used for all operations. In case of doubt, is the one created by default when you create the RDS Cluster (might be hidden in your Terraform state).</li><li><strong>Decide which version your team wants to update it to</strong>. Most cloud providers allow you to jump multiple versions (in our case, we went from 10 to 14).</li><li><strong>Run a test suite against the desired version and let it soak in development environments for a while.</strong> Although rare, there might be changes that affect your code.</li><li><strong>Create a new set of</strong> <a href=https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/parameter-groups-overview.html><strong>parameter groups</strong></a> <strong>for the desired version.</strong> It can be done in Terraform (<a href=https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/rds_cluster_parameter_group>cluster</a> and <a href=https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_parameter_group>instances</a>) or in the UI. Having it in Terraform makes it easier to replicate these steps later.</li><li><strong>Ensure SOURCE and TARGET live in the same network and correctly set outbound/inbound firewalls.</strong> It&rsquo;s trivial, but you never know if someone has changed something manually (our case).</li><li><strong>Ensure all tables have replica identity correctly set or have a primary key.</strong></li><li><a href=https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.PostgreSQL.html#USER_UpgradeDBInstance.PostgreSQL.MajorVersion.Process><strong>Read the AWS Postgres upgrade guide</strong></a> to get familiarised with its usual process.</li></ol><h2 id=data-integrity>Data integrity<a hidden class=anchor aria-hidden=true href=#data-integrity>#</a></h2><p>The engineering team could only be confident if we proved that the data integrity was kept after the upgrade. We came up with a few scripts which were consolidated in a tool available at <a href=https://github.com/processout/pg-upgrade-data-check><code>processout/pg-upgrade-data-check</code></a>.</p><p>The script compares data from before the replication and after the replication, comparing the hash of all rows in the between the time the database was replicating. It detected issues multiple times in both testing and production rollouts. The caveat is that it relies on an autoincremental key, not working if your tables don&rsquo;t have one.</p><p>In any case, even if this tool does not suit you, <strong>it is very important that the team defines a strategy to prove the data has been kept intact</strong>.</p><h2 id=preparing-the-source-for-replication>Preparing the SOURCE for replication<a hidden class=anchor aria-hidden=true href=#preparing-the-source-for-replication>#</a></h2><ol><li>The cluster needs to have logical replication enabled. On AWS RDS, <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.Replication.Logical.html#:~:text=In%20the%20Parameters%20search%20field%2C%20type%20rds%20to%20find%20the%20rds.logical_replication%20parameter.%20The%20default%20value%20for%20this%20parameter%20is%200%2C%20meaning%20that%20it%27s%20turned%20off%20by%20default.">set <code>rds.logical_replication=1</code> in parameter groups</a>. The native equivalent <a href=https://www.postgresql.org/docs/current/runtime-config-wal.html>is setting <code>wal_level=logical</code></a>. Once configured, restart the instances (be careful with the order and failovers).</li><li>Connect to the SOURCE writer instance and confirm that the WAL level is <code>logical</code> by running <code>show wal_level</code>. If it is not, reboot the SOURCE writer instance.</li><li>Create a replication role and grant the correct access.</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>USER</span> replicator <span style=color:#66d9ef>WITH</span> password <span style=color:#e6db74>&#39;password&#39;</span>; <span style=color:#75715e>-- replace this
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>GRANT</span> rds_replication <span style=color:#66d9ef>TO</span> replicator; <span style=color:#75715e>-- AWS RDS specific
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>GRANT</span> <span style=color:#66d9ef>USAGE</span> <span style=color:#66d9ef>ON</span> <span style=color:#66d9ef>SCHEMA</span> <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>TO</span> replicator; <span style=color:#75715e>-- the default for Postgres is &lt;public&gt;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>GRANT</span> <span style=color:#f92672>&lt;</span>target_database<span style=color:#f92672>&gt;</span> <span style=color:#66d9ef>TO</span> replicator;
</span></span><span style=display:flex><span><span style=color:#66d9ef>GRANT</span> <span style=color:#66d9ef>SELECT</span> <span style=color:#66d9ef>ON</span> <span style=color:#66d9ef>ALL</span> TABLES <span style=color:#66d9ef>IN</span> <span style=color:#66d9ef>SCHEMA</span> <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>TO</span> replicator;
</span></span></code></pre></div><ol start=4><li>If you have any data integrity script, you should run it now. This is because it will capture the state before you start accumulating WAL.</li><li>Create a publication: This is used by the target database to subscribe for changes.</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> PUBLICATION pub1 <span style=color:#66d9ef>FOR</span> <span style=color:#66d9ef>ALL</span> TABLES;
</span></span></code></pre></div><ol start=6><li>Create a replication slot: The write operations will be accumulated in this slot. It will spill out the LSN it started to capture, and it might be handy to keep a note of that.</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> pg_create_logical_replication_slot(<span style=color:#e6db74>&#39;rep_slot_001&#39;</span>, <span style=color:#e6db74>&#39;pgoutput&#39;</span>);
</span></span></code></pre></div><ol start=7><li>At this point, you can already see replication slot stats by doing the following queries:</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#75715e>-- General details about it
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_replication_slots;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- I mostly used the one below to identify the lag
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> slot_name, pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(),restart_lsn)) <span style=color:#66d9ef>AS</span> replicationSlotLag, active <span style=color:#66d9ef>FROM</span> pg_replication_slots;
</span></span></code></pre></div><h2 id=create-the-target-database>Create the target database<a hidden class=anchor aria-hidden=true href=#create-the-target-database>#</a></h2><p><strong>The target will be a clone of the source.</strong> If you are unfamiliar with this concept, look at <a href=https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Clone.html>the RDS Aurora cloning guide</a>. I haven&rsquo;t tested it, but it might also work with native restore.</p><ol><li>Clone the source database: <a href=https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Clone.html#Aurora.Managing.Clone.create>the UI makes it very simple</a>, but check all parameters set up. <a href=https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/rds_cluster#restore_to_point_in_time-argument-reference>Another way is leveraging Terraform for that</a>.</li><li>Once the clone is finished, check the writer instance logs. You should see one of the three messages:</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>... invalid record length at 136/DFC70140: wanted 24, got <span style=color:#ae81ff>0</span> <span style=color:#75715e># usually it always worked with this one</span>
</span></span><span style=display:flex><span>... invalid resource manager ID <span style=color:#ae81ff>48</span> at 3/1B9AF790
</span></span></code></pre></div><p>This is <strong>the LSN the target writer instance started with: keep note of this</strong>. It will never match the one from the <code>pg_create_logical_replication_slot</code> output as more operations went through between its creation and the clone. The LSN output will allow you to indicate Postgres to skip all operations up to a certain point after the upgrade, which is the trick of this process. If you don&rsquo;t set it, you might have duplicated data or unique constraint failures.</p><p>Connect to the target and drop the publication and replication slot, as the Aurora clone will also bring those over. <strong>If you don&rsquo;t delete them,</strong> <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.PostgreSQL.html#USER_UpgradeDBInstance.PostgreSQL.MajorVersion.Process:~:text=Handle%20logical%20replication%20slots"><strong>the pre-upgrade checks will fail</strong></a><strong>.</strong></p><pre tabindex=0><code>DROP PUBLICATION pub1;
SELECT pg_drop_replication_slot(&#39;rep_slot_001&#39;) from pg_replication_slots;
</code></pre><p><strong>Time to upgrade:</strong> Upgrade to the desired version through the UI or terraform, remembering to double-check all the pre-filled settings. <strong>Remember that you need a new set of parameter groups, as each version has its own (pre-setup step 4).</strong> The upgrade will likely take 15-20 minutes.</p><p>Once finished, check if the writer&rsquo;s <code>show wal_level</code> is set to <code>logical</code>. If not, an extra restart will be required on the writer. This was an issue (probably an AWS bug) in all upgrades.</p><p>Before the final steps, don&rsquo;t forget the following:</p><ol><li><strong>Run <code>ANALYSE</code>:</strong> All table statistics are wiped after an upgrade. Those are used to plan queries correctly, and Postgres&rsquo; performance might be terrible without them.</li><li><strong>Run <code>VACUUM</code>:</strong> This is optional, but if it has been a while since it has been done, this is an excellent opportunity (no live traffic).</li><li><strong>Run benchmarks:</strong> Pick the heaviest and most frequent queries and run some benchmarks against them (post-ANALYSE). The results should be the same, if not better.</li></ol><h2 id=setup-replication-between-source-and-target>Setup replication between SOURCE and TARGET<a hidden class=anchor aria-hidden=true href=#setup-replication-between-source-and-target>#</a></h2><p>At this point, around 1-2 hours have passed since the replication slot creation. Your clone only has the data until that point. The following steps will flush all operations from the SOURCE into the TARGET, and at the end, both databases should have the same dataset.</p><ol><li><strong>Create the subscription in the target Postgres.</strong> You must replace all <code>$</code> with the correct values. Depending on your Postgres logging setup, <strong>this command might be logged with the plain password (<code>log_statement=ddl</code>, <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.Concepts.PostgreSQL.html#:~:text=Logs%20all%20data%20definition%20language%20(DDL)%20statements%2C%20such%20as%20CREATE%2C%20ALTER%2C%20DROP%2C%20and%20so%20on.">for example</a>)</strong>. The team might be fine to have this password leaked in logs during the whole upgrade process, but remember to delete the account afterwards.</li></ol><pre tabindex=0><code>
CREATE SUBSCRIPTION sub1 CONNECTION &#39;host=$source_url user=replicator dbname=$db_name password=$replicator_password&#39; PUBLICATION pub1 WITH (
    copy_data = false, -- disable initial COPY
    create_slot = false, -- disable replication_slot creation on PUBLISHER
    enabled = false, -- disabled by default, as we want to tweak the LSN
    connect = true, -- try to connect to the SOURCE
    slot_name = &#39;rep_slot_001&#39; -- change this according to the replication slot used
);
</code></pre><ol start=2><li>Check if there were no network or access issues through the Postgres logs. Sometimes, it simply hangs on the <code>CREATE SUBSCRIPTION</code> if the SOURCE can&rsquo;t be reached <strong>(see pre-setup step 5)</strong>.</li><li>Advance the SUBSCRIPTION LSN to the value returned on the TARGET boot. As already observed, this will skip operations that would result in duplicated data. <strong>The caveat is that the LSN returned there is sometimes a bit ahead of what it should be, resulting in skipped legit operations. That is why having a data integrity script is very important!</strong></li></ol><pre tabindex=0><code>SELECT pg_replication_origin_advance(
    (SELECT &#39;pg_&#39;||oid::text AS &#34;external_id&#34; FROM pg_subscription WHERE subname = &#39;sub1&#39; LIMIT 1),
    $LSN_FROM_STEP_1
);
</code></pre><ol start=4><li>Enable the subscription by executing <code>ALTER SUBSCRIPTION sub1 ENABLE;</code>.</li><li>On the SOURCE, observe the replication slot statistics. It will show the WAL logs being consumed, with the lag between the current LSN and slot LSN decreasing.</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> slot_name, pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(),restart_lsn)) <span style=color:#66d9ef>AS</span> replicationSlotLag, active <span style=color:#66d9ef>FROM</span> pg_replication_slots;
</span></span><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_stat_replication;
</span></span></code></pre></div><ol start=6><li>The operations will have been all flushed once the lag is around kilobytes. <strong>Run your data integrity scripts at this point, as both should contain the same data (with a minor lag).</strong></li></ol><h2 id=finishing-the-process-the-switch>Finishing the process: the switch<a hidden class=anchor aria-hidden=true href=#finishing-the-process-the-switch>#</a></h2><p>At this point, both databases will have the same dataset. All this can be done during work hours, while the switch can be done during off-peak.</p><p>You can monitor its progress by using one of the following queries:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#75715e>--
</span></span></span><span style=display:flex><span><span style=color:#75715e>-- General sync state
</span></span></span><span style=display:flex><span><span style=color:#75715e>--
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Q1: Size per table (useful to spot discrepancies after syncing)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#66d9ef>table_name</span>, pg_relation_size(quote_ident(<span style=color:#66d9ef>table_name</span>)), pg_size_pretty(pg_relation_size(quote_ident(<span style=color:#66d9ef>table_name</span>)))
</span></span><span style=display:flex><span><span style=color:#66d9ef>FROM</span> information_schema.tables
</span></span><span style=display:flex><span><span style=color:#66d9ef>WHERE</span> table_schema <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;public&#39;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>ORDER</span> <span style=color:#66d9ef>BY</span> <span style=color:#ae81ff>2</span> <span style=color:#66d9ef>DESC</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Q2: Total table sizes without indexes (useful to spot discrepancies after syncing)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#66d9ef>SUM</span>(pg_relation_size(quote_ident(<span style=color:#66d9ef>table_name</span>))) <span style=color:#66d9ef>FROM</span> information_schema.tables <span style=color:#66d9ef>WHERE</span> table_schema <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;public&#39;</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>--
</span></span></span><span style=display:flex><span><span style=color:#75715e>-- SOURCE setup
</span></span></span><span style=display:flex><span><span style=color:#75715e>--
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Q3 &amp; Q4: Details about the SOURCE publication
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_publication;
</span></span><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_publication_tables;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Q5: Get SOURCE LSN (useful to compare with the TARGET LSN)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> pg_current_wal_lsn();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>--
</span></span></span><span style=display:flex><span><span style=color:#75715e>-- SOURCE monitoring
</span></span></span><span style=display:flex><span><span style=color:#75715e>--
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Q6: Lag between publisher x subscriber
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> slot_name, pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(),restart_lsn)) <span style=color:#66d9ef>AS</span> replicationSlotLag, active <span style=color:#66d9ef>FROM</span> pg_replication_slots;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Q7: Data about replication slots
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_replication_slots;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Q8: Data about SOURCE replication status (like lag &amp; current state)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_stat_replication;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>--
</span></span></span><span style=display:flex><span><span style=color:#75715e>-- TARGET monitoring
</span></span></span><span style=display:flex><span><span style=color:#75715e>--
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Q9: Active subscription state and configs (similar to pg_publicationn on the SOURCE)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_subscription;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Q10: Details on active TARGET subscriptions
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> pg_stat_subscription;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- More here: https://dba.stackexchange.com/questions/314324/monitor-logical-replication-using-lsn
</span></span></span></code></pre></div><p>Every company has a different setup, but this is what will be required in broad lines:</p><ol><li><strong>Stop incoming traffic to the database:</strong> scale down the application using it or create a circuit breaker where it is being used.</li><li><strong>Change environment variables:</strong> point to the new database</li><li><strong>Wait for flush:</strong> there might be some in-flight WAL logs. Refer to the above queries to monitor the progress. Ideally the replication slot should be almost empty (around * kB of data)</li><li><strong>Disable subscription:</strong> <code>ALTER SUBSCRIPTION sub1 DISABLE;</code></li><li><strong>Sync all fields using a sequence:</strong> doing this through a SQL script is recommended, as more time spent here = more downtime. The following script can be used</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Creates script</span>
</span></span><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt; EOT &gt;&gt; ./fix_sequences.sql
</span></span></span><span style=display:flex><span><span style=color:#e6db74>SELECT &#39;SELECT SETVAL(&#39; || quote_literal(s.sequence_schema || &#39;.&#39; || s.sequence_name) || &#39;, COALESCE(MAX(id), 1)) FROM &#39; || quote_ident(t.table_schema) || &#39;.&#39; || quote_ident(t.table_name) || &#39;;&#39; as sql
</span></span></span><span style=display:flex><span><span style=color:#e6db74>FROM information_schema.sequences s
</span></span></span><span style=display:flex><span><span style=color:#e6db74>JOIN information_schema.tables t ON t.table_name = REPLACE(sequence_name, &#39;_id_seq&#39;, &#39;&#39;) AND t.table_schema = s.sequence_schema
</span></span></span><span style=display:flex><span><span style=color:#e6db74>ORDER BY sequence_name ASC;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>-- This could be used as well: https://wiki.postgresql.org/wiki/Fixing_Sequences
</span></span></span><span style=display:flex><span><span style=color:#e6db74>-- But it missed some sequences when I tried
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOT</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Query database and generate sequences to be fixed</span>
</span></span><span style=display:flex><span>psql -Atq -f ./fix_sequences.sql -o ./fix_sequences.gen.sql $target_url
</span></span><span style=display:flex><span>psql -f ./fix_sequences.gen.sql $target_url
</span></span></code></pre></div><ol start=6><li><strong>Restart traffic to the database:</strong> If everything goes right, you should be ready to re-enable connections to it.</li></ol><p>Between (5) and (6), you can set up a &ldquo;reverse logical replication&rdquo;, which might help in case of rollback. SOURCE becomes the TARGET, and TARGET becomes the SOURCE. If you want to set this up, script it so you can reduce downtime.</p><h2 id=the-end>The end?<a hidden class=anchor aria-hidden=true href=#the-end>#</a></h2><p>If everything goes right, no data is lost, and there is minimal downtime, the team and stakeholders will be happy. This is a reminder: Postgres releases new versions yearly, and AWS will keep phasing old versions out annually. Until a major upgrade allows an easier upgrade path, be prepared for this process more than once in your lifetime 🥲</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://brunoluiz.net/blog/2022/nov/low-downtime-postgres-upgrade-i-want-to-believe/><span class=title>Next »</span><br><span>Low downtime Postgres upgrade: I want to believe (part I)</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://brunoluiz.net/>Bruno Luiz Silva</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>